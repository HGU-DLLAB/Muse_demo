<!DOCTYPE html>
<html lang="en">
<head>
<title>W3.CSS Template</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<script defer src="https://pyscript.net/latest/pyscript.js"></script>
<py-env>
  - path:
    - main.py
</py-env>
<style>
body {font-family: "Lato", sans-serif}
.mySlides {display: none}
#add_todo {margin-left: 5px}
#demo_page:hover{
  background: silver;
}
table {color: black; font-size: 15px}
</style>
</head>
<body>

<!-- Navbar -->
<div class="w3-top">
  <div class="w3-bar w3-black w3-card">
    <a class="w3-bar-item w3-button w3-padding-large w3-hide-medium w3-hide-large w3-right" href="javascript:void(0)" onclick="myFunction()" title="Toggle Navigation Menu"><i class="fa fa-bars"></i></a>
    <a href="#" class="w3-bar-item w3-button w3-padding-large">HOME</a>
    <a href="#band" class="w3-bar-item w3-button w3-padding-large w3-hide-small">INTRODUCTION</a>
    <a href="#tour" class="w3-bar-item w3-button w3-padding-large w3-hide-small">AUDIO DEMO</a>
    <!-- <a href="#contact" class="w3-bar-item w3-button w3-padding-large w3-hide-small">MORE DETAILS</a> -->
    <!-- <div class="w3-dropdown-hover w3-hide-small">
      <button class="w3-padding-large w3-button" title="More">Developers <i class="fa fa-caret-down"></i></button>     
      <div class="w3-dropdown-content w3-bar-block w3-card-4">
        <a href="#" class="w3-bar-item w3-button">Developers</a>
      </div>
    </div> -->
    <!-- <a href="javascript:void(0)" class="w3-padding-large w3-hover-red w3-hide-small w3-right"><i class="fa fa-search"></i></a> -->
  </div>
</div>

<!-- Navbar on small screens (remove the onclick attribute if you want the navbar to always show on top of the content when clicking on the links) -->
<div id="navDemo" class="w3-bar-block w3-black w3-hide w3-hide-large w3-hide-medium w3-top" style="margin-top:46px">
  <a href="#band" class="w3-bar-item w3-button w3-padding-large" onclick="myFunction()">BAND</a>
  <a href="#tour" class="w3-bar-item w3-button w3-padding-large" onclick="myFunction()">TOUR</a>
  <a href="#contact" class="w3-bar-item w3-button w3-padding-large" onclick="myFunction()">CONTACT</a>
  <a href="#" class="w3-bar-item w3-button w3-padding-large" onclick="myFunction()">MERCH</a>
</div>

<!-- Page content -->
<div class="w3-content" style="max-width:2000px;margin-top:46px">

  <!-- Automatic Slideshow Images -->
  <div class="mySlides w3-display-container w3-center">
    <img src="image_audio/Muse.PNG" style="width:100%">
    <div class="w3-display-bottommiddle w3-container w3-text-white w3-padding-32 w3-hide-small">
    </div>
  </div>
  <div class="mySlides w3-display-container w3-center">
    <img src="image_audio/subtitle.png" style="width:100%">
    <div class="w3-display-bottommiddle w3-container w3-text-white w3-padding-32 w3-hide-small">
    </div>
  </div>


  <!-- The Band Section -->
  <div class="w3-container w3-content w3-center w3-padding-64" style="max-width:800px" id="band">
    <h2 class="w3-wide"><b>MuSE-SVS</b></h2>
    <p class="w3-opacity"><i>Multi Singer Emotional Singing Voice Synthesizer that Controls Emotional Intensity</i></p>
    <p class="w3-justify">We propose a multi-singer emotional singing voice
      synthesizer, <b>Muse-SVS</b>, that expresses emotion at various intensity levels by controlling subtle changes in pitch and phoneme
      length while accurately following the lyrics, pitch, and phoneme
      length of the score. To control multiple style attributes avoiding
      loss of fidelity and expressiveness due to interference between
      attributes, Muse-SVS represents all attributes and their relations
      together by a joint embedding in a unified embedding space.
      Muse-SVS can express emotional intensity not in the training
      data, including even stronger emotions than those in the training
      data, through emotion embedding interpolation and extrapolation. We also propose a statistical pitch predictor to express pitch
      variance according to emotional intensity and a context-aware
      residual duration predictor to prevent the accumulation of variances in phoneme duration, which is crucial for synchronization
      when synthesizing long singing voices. In addition, we propose
      a novel ASPP-Transformer to improve fidelity and expressiveness by referring to broad contexts. In experiments, Muse-SVS
      exhibited improved fidelity, expressiveness, and synchronization
      performance compared with the baseline models. The results of
      quantitative evaluation and visualization analysis show that the
      proposed methods effectively express the variance in pitch and
      phoneme duration according to emotional intensity. To the best
      of our knowledge, Muse-SVS is the first singing voice synthesizer
      capable of controlling emotional intensity.
      <!-- <a style='text-align: center; font-size: 15px; color: #9F8772;' href="https://arxiv.org/pdf/2203.00931.pdf" > U-Singer Paper link</a> -->
      </p>
  </div>

  <div class="images" id="images" style="text-align: center;">
    <table align="center">
      <tr>
        <td><img src="image_audio/model_structure.PNG" style="width:650px"/></td><td><img src="image_audio/VA.png" style="width:600px"/></td>
      <tr>
      <tr>
        <td align="center">Model Overall Structure</td><td align="center">Variance Adaptor Structure</td>
      </tr>
    </table>
    <br><br><br><br>
  </div>
  <!-- The Tour Section -->
  <div class="w3-black" id="tour">
    <div class="w3-container w3-content w3-padding-64" style="max-width:1600px">
      <h2 class="w3-wide w3-center">Demo</h2>
      <ul class="w3-ul w3-border w3-white w3-text-grey">
        <li class="w3-padding" style="font-size: 20px;  text-align:center; color:black;">Comparison to Baseline Models<br>
          <p style="font-size: 18px; color:black; text-align:left;">Because MuSE-SVS is the first mutli-singer emotional SVS model, there is no exisiting baselnie model to compare fairly. Therefore, we built two multi-singer emotional SVS models by extending FastSpeech2 and VISinger to multi-singer and multi-emotional models, and named then ‘extFFTSinger’ and ‘extVISinger’. These audio samples are the results of training MuSE-SVS and baseline models to learn embeddings of multi-singer, multi-emotion and multi-intensity. If you need more details of baseline models, please check the paper.</p>
          <p style="font-size: 18px; color:black; text-align:center;">Samples of male singer (Sad)</p>
          <table align="center">
            <colgroup span="5" class="columns"></colgroup>
            <tr align="center">
              <th></th>
              <th>Neutral</th>
              <th>Sad 0.3</th>
              <th>Sad 0.7</th>
              <th>Sad 1.0</th>
            </tr>
            <tr>
              <td><b>MuSE-SVS</b></td>
              <td><audio controls src="image_audio/Muse_SVS/M2_sad010_26_00.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/Muse_SVS/M2_sad010_26_03.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/Muse_SVS/M2_sad010_26_07.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/Muse_SVS/M2_sad010_26_10.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
            </tr>
            <tr>
              <td><b>extVISinger</b></td>
              <td><audio controls src="image_audio/VISinger/M2_sad010_26_00.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/VISinger/M2_sad010_26_03.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/VISinger/M2_sad010_26_07.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/VISinger/M2_sad010_26_10.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
            </tr>
            <tr>
              <td><b>extFFTSinger</b></td>
              <td><audio controls src="image_audio/FFTSinger/M2_sad010_26_00_vocgan_spk-4_emo-0.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/FFTSinger/M2_sad010_26_03_vocgan_spk-4_emo-4.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/FFTSinger/M2_sad010_26_07_vocgan_spk-4_emo-5.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/FFTSinger/M2_sad010_26_10_vocgan_spk-4_emo-6.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
            </tr>
          </table>
          <br><br>
          <p style="font-size: 18px; color:black; text-align:center;">Samples of female singer (Happy)</p>
          <table align="center">
            <colgroup span="5" class="columns"></colgroup>
            <tr align="center">
              <th></th>
              <th>Neutral</th>
              <th>Happy 0.3</th>
              <th>Happy 0.7</th>
              <th>Happy 1.0</th>
            </tr>
            <tr>
              <td><b>MuSE-Singer</b></td>
              <td><audio controls src="image_audio/Muse_SVS/F2_joy015_06_00.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/Muse_SVS/F2_joy015_06_03.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/Muse_SVS/F2_joy015_06_07.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/Muse_SVS/F2_joy015_06_10.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
            </tr>
            <tr>
              <td><b>extVISinger</b></td>
              <td><audio controls src="image_audio/VISinger/F2_joy015_06_00.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/VISinger/F2_joy015_06_03.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/VISinger/F2_joy015_06_07.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/VISinger/F2_joy015_06_10.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
            </tr>
            <tr>
              <td><b>extFFTSinger</b></td>
              <td><audio controls src="image_audio/FFTSinger/F2_joy015_06_00_vocgan_spk-3_emo-0.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/FFTSinger/F2_joy015_06_03_vocgan_spk-3_emo-1.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/FFTSinger/F2_joy015_06_07_vocgan_spk-3_emo-2.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/FFTSinger/F2_joy015_06_10_vocgan_spk-3_emo-3.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
            </tr>
          </table>
         
        </li>

        <!-- Statistical Pitch Predictor -->
        <li class="w3-padding" style="font-size: 20px;  text-align:center; color:black;">Statistical Pitch Predictor<br>
          <p style="font-size: 18px; color:black; text-align:left;">Statistical pitch predictor estimates the distribution of the F0 frequencies at the phoneme level.
            The pitch predictor consists of a pitch mean predictor and a pitch variance predictor and estimates the local mean <var>µ<sub>i</sub></var> and local variance <var>σ<sub>i</sub><sup>2</sup></var> of the F0 frequencies within the interval of each phoneme y<sub>i</sub>
            Both predictors take as input the joint embedding <var>E(y<sub>i</sub>, z<sub>1</sub>,z<sub>2</sub>)</var> to reflect the influence of singer ID (<var>z<sub>1</sub></var>) and emotional intensity (<var>z<sub>2</sub></var>).
            To reliably estimate mean pitch, the pitch mean predictor <var>Pred<sub>pm</sub>(&#183;)</var> estimates mean pitch <var>µ&#770;<sub>i</sub></var> indirectly by first predicting the residual <var>r&#770;<sub>i</sub></var> between the note pitch <var>p<sub>i</sub></var> and the ground truth mean pitch <var>µ<sub>i</sub></var> measured from the training sample and then adding the predicted residual to the note pitch as <var>µ&#770;<sub>i</sub> = p<sub>i</sub> + <var>r&#770;<sub>i</sub></var></var>
            The pitch variance predictor <var>Pred<sub>pcv</sub>(&#183;)</var> predicts the coefficient of variances <var>CV<sub>i</sub> = σ<sub>i</sub> / µ<sub>i</sub></var> because <var>CV<sub>i</sub></var> removes the correlation with pitch mean by normalization and therefore is more reliably predictable. </p>
    
            
          <img src="image_audio/statisticalPP.PNG" style="width:900px;"/>
          <p style="font-size: 15px; color:black;">The F0 contours  (blue solid line) of a female singer’s
            voices with emotional intensity levels neutral (left) and
            sad1.0(right).</p>
          <table align="center">
            <colgroup span="5" class="columns"></colgroup>
            <tr align="center">
              <th></th>
              <th>Neutral</th>
              <th>Sad 1.0</th>
            </tr>
            <tr>
              <td><b>G.T.</b></td>
              <td><audio controls src="image_audio/GT/F2_sad010_05_00.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <!-- GT vocgan 통과시킨걸로 교체해야함 -->
              <td><audio controls src="image_audio/GT/F2_sad010_05_10.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
            </tr>
            <tr>
              <td><b>Deterministic Pitch Predictor(conventional)</b></td>
              <td><audio controls src="image_audio/Muse_SVS/F2_sad010_05_00(convention).wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/Muse_SVS/F2_sad010_05_10(convention).wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
            </tr>
            <tr>
              <td><b>Statistical Pitch Predictor(proposed)</b></td>
              <td><audio controls src="image_audio/Muse_SVS/F2_sad010_05_00.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/Muse_SVS/F2_sad010_05_10.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
            </tr>

          </table>
        </li>

        <!-- CRDP -->
        <li class="w3-padding" style="font-size: 20px;  text-align:center; color:black;">Context-aware Residual Duration Predictor(CRDP)<br>
          <p style="font-size: 18px; color:black; text-align:left;">CRDP minimizes synchronization error by considering cumulative duration up to the previous phoneme when predicting the next phoneme duration hwile imitating variances in training samples to express emotion for individual phonemes.
            CRDP predicts the duration of phonemes sequentially with an autoregressive structure. When it predicts the duration of a phoneme, it takes the synchronization error of the previous phoneme and predicts the next phoneme duration inclined to compensate for the synchronization error at the previous step.
            At each step, CRDP takes the joint embedding <var>E(y<sub>i</sub>,z<sub>1</sub>,z<sub>2</sub>)</var> to reflect the influence of singer ID and emotional intensity.
            CRDP also takes the synchronization error of the previous step <var>SyncErr(i-1)</var> as input.
            CRDP learns to estimate residual duration <var>s<sub>i</sub> = d<sub>i</sub> - d&#772;<sub>i</sub></var> as <var>s&#770;<sub>i</sub> = Pred<sub>d(i)</sub>(E(y<sub>i</sub>,z<sub>1</sub>,z<sub>2</sub>), SyncErr(i-1))</var>.
            Then, CRDP adds the predicted residual to the note duration as <var>d&#770;<sub>i</sub> = d&#772;<sub>i</sub> + s&#770;<sub>i</sub></var>.
            <br></p>
            
          <img src="image_audio/crdp_graph.PNG" style="width:700px;"/>
          <p style="font-size: 15px; color:black;">The synchronization errors of duration predictors for
            a long song composed of 117 notes whose length is 67.08
            seconds.</p>
          <!-- <table align="center">
            <colgroup span="5" class="columns"></colgroup>
            <tr align="center">
              <th></th>
              <th>Neutral</th>
              <th>Sad 1.0</th>
            </tr>
            <tr>
              <td><b>G.T.</b></td>
              <td><audio controls src="image_audio/GT/F2_sad010_05_00.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/GT/F2_sad010_05_10.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
            </tr>
            <tr>
              <td><b>Deterministic Pitch Predictor(conventional)</b></td>
              <td><audio controls src="image_audio/Muse_SVS/F2_sad010_05_00(convention).wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/Muse_SVS/F2_sad010_05_10(convention).wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
            </tr>
            <tr>
              <td><b>Statistical Pitch Predictor(proposed)</b></td>
              <td><audio controls src="image_audio/Muse_SVS/F2_sad010_05_00.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/Muse_SVS/F2_sad010_05_10.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
            </tr>

          </table> -->
        </li>

        
        <!-- ASPP -->
        <li class="w3-padding" style="font-size: 20px;  text-align:center; color:black;">ASPP-Transformer<br>
          <p style="font-size: 18px; color:black; text-align:left;">ASPP-Transformer is extended FFT by replacing convolution iwth atrous spatial pyramid pooling (ASPP), as shown in the figure. It inherits the advantages of ASPP in that it can refer to a broad context with minimal increases in computation and parameters. To focus on the local neighborhoods while incorporatiing a broad context, we assign a large number of channels to the filters with low atrous rates.<br></p>
          <img src="image_audio/ASPP_fig.PNG" style="width:700px;"/>
          <p style="font-size: 15px; color:black;">The effective receptive fields of the proposed ASPP-Transformer and the conventional Transformer.</p>
          <table align="center">
            <colgroup span="5" class="columns"></colgroup>
            <tr align="center">
              <th>ASPP-Transformer</th>
              <th>Transformer</th>
            </tr>
            <tr>
              <td><audio controls src="image_audio/Muse_SVS/F2_sad010_11_10.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/Muse_SVS/F2_sad010_11_10(wout_ASPP).wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
            </tr>

          </table>
        </li>

        <!-- Interpolation and extrapolation -->
        <li class="w3-padding" style="font-size: 20px;  text-align:center; color:black;">Interpolation and Extrapolation<br>
          <p style="font-size: 18px; color:black; text-align:left;">Muse-SVS applies emotion embedding interpolation. It learns only three embeddings, each of which is for <var>happy<sub>0.1</sub></var>, <var>neutral</var>, and <var>sad<sub>0.1</sub></var>, and computes the embeddings of intermediate intensity levels by interpolation as <var>r<sub>happy<sub>t</sub></sub> = t*r<sub>happy<sub>1.0</sub></sub> + (1-t)*r<sub>neutral</sub></var>&nbsp;&nbsp;&nbsp;and&nbsp;&nbsp;&nbsp;<var>r<sub>sad<sub>t</sub></sub> = t*r<sub>sad<sub>1.0</sub></sub> + (1-t)*r<sub>neutral</sub></var> . 
            <br>It has multiple advantages: first, it is possilbe to express intermediate intensity levels, such as <var>happy<sub>0.5</sub></var> and <var>sad<sub>0.8</sub></var>, that are not in the training data. 
            Furthermore, it enalbes the synthesis of singing voices with emotional intensities beyond those in the training data by emotion embedding extrapolation with <var>t > 1</var>.
            Third, applying emotion embedding interpolation during training leads the model to reflect the neighborhood relation between emotional intensity levels and thereby to learn a linear embedding space, as shown in a figure.
          </p>
          <img src="image_audio/embedding_space.png" style="width:300px;"/>
          <p style="font-size: 15px; color:black;">Embedding Space</p>
          <table align="center">
            <colgroup span="5" class="columns"></colgroup>
            <tr align="center">
              <th></th>
              <th>Neutral</th>
              <th>Happy 0.5 (Interpolation)</th>
              <th>Happy 1.0</th>
              <th>Happy 1.7 (Extrapolation)</th>
            </tr>
            <tr>
              <td><b>MuSE-SVS</b></td>
              <td><audio controls src="image_audio/Muse_SVS/F2_joy015_05_0.0.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/Muse_SVS/F2_joy015_05_0.5.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/Muse_SVS/F2_joy015_05_1.0.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
              <td><audio controls src="image_audio/Muse_SVS/F2_joy015_05_1.7.wav">해당 브라우저는 audio를 지원하지 않습니다.</audio></td>
            </tr>
          </table>
        </li>
        <li class="w3-padding" style="font-size: 20px;  text-align:center; color:black;">Synthesized Singing Voice with MIDI<br>
          <p style="font-size: 18px; color:black; text-align:left;">This audio sample is the result of concation of multiple singing voice samples which are syntheiszed by same song but different part of each. We add MIDI of the song to the audio sample of singing voice.</p>
          <audio controls src="image_audio/svs1.mp3">해당 브라우저는 audio를 지원하지 않습니다.</audio>
        </li>
      </ul>

    </div>
  </div>

<!-- End Page Content -->
</div>

<!-- Image of location/map -->
<!-- <img src="/w3images/map.jpg" class="w3-image w3-greyscale-min" style="width:100%"> -->

<!-- Footer -->
<footer class="w3-container w3-padding-64 w3-center w3-opacity w3-light-grey w3-xlarge">
  <p class="w3-medium">Powered by <a href="https://www.w3schools.com/w3css/default.asp" target="_blank">w3.css</a></p>
</footer>

<script>
// Automatic Slideshow - change image every 4 seconds
var myIndex = 0;
carousel();

function carousel() {
  var i;
  var x = document.getElementsByClassName("mySlides");
  for (i = 0; i < x.length; i++) {
    x[i].style.display = "none";  
  }
  myIndex++;
  if (myIndex > x.length) {myIndex = 1}    
  x[myIndex-1].style.display = "block";  
  setTimeout(carousel, 4000);    
}

// Used to toggle the menu on small screens when clicking on the menu button
function myFunction() {
  var x = document.getElementById("navDemo");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else { 
    x.className = x.className.replace(" w3-show", "");
  }
}

// When the user clicks anywhere outside of the modal, close it
var modal = document.getElementById('ticketModal');
window.onclick = function(event) {
  if (event.target == modal) {
    modal.style.display = "none";
  }
}
</script>

</body>
</html>
